{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pepto-GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOOjTJRaGdO4Skz+F65Es3t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjatkin/Pepto-GAN/blob/master/Pepto_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t762oxqgVgiB",
        "colab_type": "text"
      },
      "source": [
        "# Imports for everything here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aj0rDDkUNXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW3z4ZQUyC-0",
        "colab_type": "text"
      },
      "source": [
        "# Utility Functions\n",
        "\n",
        "Genral functions that have broad use across differnt sections of the code base. Should be functions rather than classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65U29R9UyPnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(peptide):\n",
        "  encodings = []\n",
        "  for aa in peptide:\n",
        "    encoding = torch.zeros(len(gan_opt.amino_acids))\n",
        "    index = gan_opt.amino_acids.index(aa)\n",
        "    encoding[index] = 1.0\n",
        "    encodings.append(encoding)\n",
        "  return torch.stack(encodings)\n",
        "\n",
        "def one_hot_s(peptides):\n",
        "  all_encodings = []\n",
        "  for peptied in peptides:\n",
        "    all_encodings.append(one_hot(peptied))\n",
        "  return torch.stack(all_encodings)\n",
        "\n",
        "def score_peptide(peptide):\n",
        "  return tox_predictor(one_hot(peptide).unsqueeze(0).cuda()).item()\n",
        "\n",
        "def decode_peptide(peptide):\n",
        "  pep = \"\"\n",
        "  for p in peptide:\n",
        "    i = p.argmax()\n",
        "    pep = pep + gan_opt.amino_acids[i]\n",
        "  \n",
        "  return pep\n",
        "\n",
        "def decode_peptide_s(peptides):\n",
        "  peps = []\n",
        "  for peptide in peptides:\n",
        "    peps.append(decode_peptide(peptide))\n",
        "  \n",
        "  return np.asarray(peps)\n",
        "\n",
        "def save_model(model, file_name):\n",
        "  torch.save(model.state_dict(), file_name)\n",
        "\n",
        "def load_model(model, file_name):\n",
        "  model.load_state_dict(torch.load(file_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J559pSfKXP8K",
        "colab_type": "text"
      },
      "source": [
        "# Network Opts\n",
        "\n",
        "This section should contain global options that configure each network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfplpNW_Xhff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Toxic Classifier Options\n",
        "\n",
        "class tox_opt():\n",
        "  n_epochs=10\n",
        "  batch_size=64\n",
        "  lr=0.0005\n",
        "  validate_every=500\n",
        "  load_network = False\n",
        "  load_model_file=\"tox_classifier.pt\"\n",
        "  save_model_file=\"tox_classifier.pt\"\n",
        "\n",
        "\n",
        "# GAN Options\n",
        "\n",
        "class gan_opt():\n",
        "  n_epochs=100\n",
        "  batch_size=64\n",
        "  lr=0.0002\n",
        "  b1=0.5\n",
        "  b2=0.999\n",
        "  latent_dim=100\n",
        "  peptide_length=7\n",
        "  amino_acids=\"CDFGHILNRSVY\"\n",
        "  d_update_every=100\n",
        "  load_discriminator=False\n",
        "  load_disc_file=\"tox_discriminatro.pt\"\n",
        "  save_disc_file=\"tox_discriminator.pt\"\n",
        "  load_generator=False\n",
        "  load_gen_file=\"tox_generator.pt\"\n",
        "  save_gen_file=\"tox_generator.pt\"\n",
        "  train_gan=True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbN0afPFWAUG",
        "colab_type": "text"
      },
      "source": [
        "# Toxic Peptide Classifier\n",
        "\n",
        "the goal of this model is to predict the toxicity score of a peptide. This can then be used to access the success of the GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3hy8qDIR2jK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------------------\n",
        "# Toxic Peptide classifier\n",
        "# -------------------------\n",
        "\n",
        "class ToxicityPredictor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ToxicityPredictor, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(int(len(gan_opt.amino_acids) * gan_opt.peptide_length), 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 1),\n",
        "    )\n",
        "\n",
        "  def forward(self, pep):\n",
        "    pep_flat = pep.view(pep.size(0), -1)\n",
        "    tox = self.model(pep_flat)\n",
        "\n",
        "    return tox\n",
        "\n",
        "# Loss function\n",
        "toxicity_loss = nn.L1Loss()\n",
        "\n",
        "# Initialize Predictor\n",
        "tox_predictor = ToxicityPredictor()\n",
        "\n",
        "if cuda:\n",
        "  tox_predictor.cuda()\n",
        "  toxicity_loss.cuda()\n",
        "\n",
        "# Optimizer\n",
        "optimizer_tox = torch.optim.Adam(tox_predictor.parameters(), lr=tox_opt.lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oWkYFPZXZn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------\n",
        "# Peptides Dataloader\n",
        "# --------------------\n",
        "class ToxicPeptideDataset(Dataset):\n",
        "  def __init__(self, file_name, labels_file_name=\"\", train=True, soft=False):\n",
        "    if soft:\n",
        "      self.peptides = self.one_soft(np.load(file_name))\n",
        "    else:\n",
        "      self.peptides = self.one_hot(np.load(file_name))\n",
        "\n",
        "    self.use_labels = False\n",
        "    if labels_file_name != \"\":\n",
        "      self.use_labels = True\n",
        "      # These come in as strings and need to be floats\n",
        "      self.labels = [float(l) for l in np.load(labels_file_name)]\n",
        "\n",
        "      # Test train split\n",
        "      split = len(self.labels) // 10\n",
        "      if train:\n",
        "        self.peptides = self.peptides[split:]\n",
        "        self.labels = self.labels[split:]\n",
        "      else:\n",
        "        self.peptides = self.peptides[:split]\n",
        "        self.labels = self.labels[:split]\n",
        "\n",
        "  def one_hot(self, peptides):\n",
        "    all_encodings = []\n",
        "    for peptide in peptides:\n",
        "      encodings = []\n",
        "      for aa in peptide:\n",
        "        encoding = torch.zeros(len(gan_opt.amino_acids))\n",
        "        index = gan_opt.amino_acids.index(aa)\n",
        "        encoding[index] = 1.0\n",
        "        encodings.append(encoding)\n",
        "      all_encodings.append(torch.stack(encodings))\n",
        "\n",
        "    return all_encodings\n",
        "  \n",
        "  def one_soft(self, peptides, alpha=0.5):\n",
        "    all_encodings = []\n",
        "    for peptide in peptides:\n",
        "      encodings = []\n",
        "      for aa in peptide:\n",
        "        cs = len(gan_opt.amino_acids)\n",
        "        encoding = torch.ones(cs) * (alpha/(cs-1))\n",
        "        index = gan_opt.amino_acids.index(aa)\n",
        "        encoding[index] = 1 - alpha\n",
        "        encodings.append(encoding)\n",
        "      all_encodings.append(torch.stack(encodings))\n",
        "\n",
        "    return all_encodings\n",
        "\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    if self.use_labels:\n",
        "      return self.peptides[index], self.labels[index]\n",
        "    return self.peptides[index]\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.peptides)\n",
        "\n",
        "tox_data_train = ToxicPeptideDataset(\"mostToxicNCSequences.npy\", \"mostToxicNCScores.npy\", train=True)\n",
        "tox_dataloader_train = torch.utils.data.DataLoader(tox_data_train, batch_size=tox_opt.batch_size, shuffle=True)\n",
        "\n",
        "tox_data_test = ToxicPeptideDataset(\"mostToxicNCSequences.npy\", \"mostToxicNCScores.npy\", train=False)\n",
        "tox_dataloader_test = torch.utils.data.DataLoader(tox_data_test, batch_size=tox_opt.batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55Z_HRfNjuhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y_hat, y_truth):\n",
        "  diff = torch.abs(y_hat-y_truth)\n",
        "  count = y_hat.size()[0]\n",
        "  return (count - torch.sum(diff))/count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAsvNAl4UVtt",
        "colab_type": "code",
        "outputId": "8ad2921c-9d8c-471e-83bf-0128282f3448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "# ------------------------------\n",
        "#  Toxicicty Predictor Training\n",
        "# ------------------------------\n",
        "\n",
        "losses = []\n",
        "v_losses = []\n",
        "acc = []\n",
        "def tox_train():\n",
        "  loop = tqdm(total=len(tox_dataloader_train) * tox_opt.n_epochs, position=0)\n",
        "  for epoch in range(tox_opt.n_epochs):\n",
        "\n",
        "      for i, (peps, toxs) in enumerate(tox_dataloader_train):\n",
        "          peps = Variable(peps.type(Tensor))\n",
        "          toxs = Variable(toxs.type(Tensor))\n",
        "          optimizer_tox.zero_grad()\n",
        "\n",
        "          y_hat = tox_predictor(peps)\n",
        "\n",
        "          # loss = toxicity_loss(y_hat.squeeze(), toxs)\n",
        "          # pdb.set_trace()\n",
        "          loss = torch.sum(torch.abs(y_hat.squeeze()-toxs))\n",
        "          loss.backward()\n",
        "          losses.append(loss.item())\n",
        "          optimizer_tox.step()\n",
        "          last_acc = 0\n",
        "          if i % tox_opt.validate_every:\n",
        "            a = []\n",
        "            for v_peps, v_toxs in tox_dataloader_test:\n",
        "              v_peps = Variable(v_peps.type(Tensor))\n",
        "              v_toxs = Variable(v_toxs.type(Tensor))\n",
        "              v_y_hat = tox_predictor(v_peps)\n",
        "              a.append(accuracy(v_y_hat.squeeze(), v_toxs).item())\n",
        "            last_acc = np.mean(a)\n",
        "            acc.append((len(losses), last_acc))\n",
        "\n",
        "          loop.set_description(\"Epoch {}, Batch {}, Toxic_Loss {:.4f}, Accuracy {:.4f}\".format(epoch, i, loss.item(), last_acc))\n",
        "          loop.update()\n",
        "\n",
        "# No need to retrain if we can just load the network from a file\n",
        "if tox_opt.load_network:\n",
        "  load_network(tox_predictor, tox_opt.load_model_file)\n",
        "  quit()\n",
        "\n",
        "tox_train()\n",
        "save_model(tox_predictor, tox_opt.save_model_file)\n",
        "\n",
        "# Plot accuracy and loss\n",
        "plt.plot(losses, label='losses')\n",
        "plt.title('Toxicicity Predictor Losses')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "a, b = zip(*acc)\n",
        "plt.plot(a, b, label='accuracy')\n",
        "plt.title('Tocicity Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 9, Batch 646, Toxic_Loss 2.4103, Accuracy 0.8782: 100%|█████████▉| 6469/6470 [07:24<00:00, 14.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-44b73a69eb1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mtox_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0msave_netwrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtox_predictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtox_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Plot accuracy and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'save_netwrok' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLI4rR3MabTN",
        "colab_type": "text"
      },
      "source": [
        "# Pepto GAN\n",
        "\n",
        "this section contains the code to run a simple gan forward on the peptide dataset. Ultimately it should produce toxic peptides as its output\n",
        "\n",
        "*be sure to re-run all the cells in this section each time the GAN is run otherwise the Generator and the Discriminator will not be re-initalized*\n",
        "\n",
        "## Tweak #1\n",
        "\n",
        "**Problem:**The generator network was really struggling to learn how to produce peptides. The probelm apeard to be that the discriminator was learning too quickly and turning the learning rate for the discriminator down enough to allow the generator to catch up was preventing the discriminator from learning useful information that would help imporve the generator. I hypothesize that the reason for this is that the one hot encodings we were using were too high contrast. Before the discriminator learning for valid peptide configurations or toxicities it instead looked only at contrast. It learned this so quickly that the generator could not adjust in time and was burried by the discriminator.\n",
        "\n",
        "**Fix:**We fixed this by using label smoothing on our one hot peptide encoding.\n",
        "\n",
        "**Result:**This resulted in a marked improvement of the GAN. the discriminator learning rate was increase by a factor of 5 (every 500 steps to every 100 steps). also the number of training epochs that the GAN was able to sustain jumped by an order of magnitued (10 epochs to 100 epocsh)\n",
        "\n",
        "## Tweak #2\n",
        "**Problem:**(See tweak #1)\n",
        "\n",
        "**Fix:**Change the contrast on the latent z vector so it's very high to see if that promotes high contrast in the output.\n",
        "\n",
        "**Result:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Zs2bIlQvX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------------------------------\n",
        "# Define the Generator and Discriminator\n",
        "# ---------------------------------------\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(gan_opt.latent_dim, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, int(gan_opt.peptide_length * len(gan_opt.amino_acids))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        pep = self.model(z)\n",
        "        pep = pep.view(pep.size()[0], gan_opt.peptide_length, len(gan_opt.amino_acids))\n",
        "        pep = F.softmax(pep, dim=2)\n",
        "        return pep\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(len(gan_opt.amino_acids) * gan_opt.peptide_length), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, pep):\n",
        "        pep_flat = pep.view(pep.size(0), -1)\n",
        "        validity = self.model(pep_flat)\n",
        "\n",
        "        return validity\n",
        "\n",
        "# Dataset\n",
        "gan_data = ToxicPeptideDataset(\"mostToxicNCSequences.npy\", soft=True)\n",
        "gan_dataloader = torch.utils.data.DataLoader(gan_data, batch_size=gan_opt.batch_size, shuffle=True)\n",
        "\n",
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=gan_opt.lr, betas=(gan_opt.b1, gan_opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=gan_opt.lr, betas=(gan_opt.b1, gan_opt.b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPkjy6hTkDZA",
        "colab_type": "code",
        "outputId": "7221c909-25c3-48b6-91d8-f9bb5fa1b355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "# --------------\n",
        "#  GAN Training\n",
        "# --------------\n",
        "\n",
        "def gan_train():\n",
        "  for epoch in range(gan_opt.n_epochs):\n",
        "\n",
        "      for i, peps in enumerate(gan_dataloader):\n",
        "\n",
        "          # Adversarial ground truths\n",
        "          valid = Variable(Tensor(peps.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "          fake = Variable(Tensor(peps.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "          # Configure input\n",
        "          real_peps = Variable(peps.type(Tensor))\n",
        "\n",
        "          # -----------------\n",
        "          #  Train Generator\n",
        "          # -----------------\n",
        "\n",
        "          optimizer_G.zero_grad()\n",
        "\n",
        "          # Sample noise as generator input\n",
        "          z = Variable(Tensor(np.random.normal(0, 1, (peps.shape[0], gan_opt.latent_dim))))\n",
        "\n",
        "          # Sample high constrast noise as generator input\n",
        "          # z = Variable(Tensor(np.random.randint(2, (peps.shape[0], gan_opt.latent_dim))))\n",
        "\n",
        "          # Generate a batch of images\n",
        "          gen_peps = generator(z)\n",
        "\n",
        "          # Loss measures generator's ability to fool the discriminator\n",
        "          g_loss = adversarial_loss(discriminator(gen_peps), valid)\n",
        "\n",
        "          g_loss.backward()\n",
        "          optimizer_G.step()\n",
        "\n",
        "          # ---------------------\n",
        "          #  Train Discriminator - every d_update_every steps\n",
        "          # ---------------------\n",
        "\n",
        "          batches_done = epoch * len(gan_dataloader) + i\n",
        "          if batches_done % gan_opt.d_update_every == 0:\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Measure discriminator's ability to classify real from generated samples\n",
        "            real_loss = adversarial_loss(discriminator(real_peps), valid)\n",
        "            fake_loss = adversarial_loss(discriminator(gen_peps.detach()), fake)\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "      print(\"epoch {}/{} d loss {:.4f}, g loss {:.4f}\".format(epoch+1, gan_opt.n_epochs, d_loss.item(), g_loss.item()))\n",
        "      for pep in gen_peps:\n",
        "        name = decode_peptide(pep)\n",
        "        score = score_peptide(name)\n",
        "        if score < -0.4 and score > -1:\n",
        "          print(\"{}: {:.6f}\".format(name, score))\n",
        "        if score <= -1:\n",
        "          print(\"#--------------------#\")\n",
        "          print(\"# {}: {:.6f} #\".format(name, score))\n",
        "          print(\"#--------------------#\")\n",
        "\n",
        "if gan_opt.load_discriminator:\n",
        "  load_model(discriminator, gan_opt.load_disc_file)\n",
        "\n",
        "if gan_opt.load_generator:\n",
        "  load_model(generator, gan_opt.load_gen_file)\n",
        "\n",
        "if gan_opt.train_gan:\n",
        "  gan_train()\n",
        "  save_model(discriminator, gan_opt.save_disc_file)\n",
        "  save_model(generator, gan_opt.save_gen_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1/100 d loss 0.6982, g loss 0.6980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a278b72bab31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgan_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0mgan_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_disc_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_gen_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-a278b72bab31>\u001b[0m in \u001b[0;36mgan_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0;31m# Loss measures generator's ability to fool the discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_peps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-fd1745ef6c34>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pep)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mpep_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mvalidity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpep_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalidity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84wV6USBCU8c",
        "colab_type": "text"
      },
      "source": [
        "# GAN evalutation\n",
        "\n",
        "Code to evaluate gan performance on several heuristics to see which setup provides the best results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMQOH3EFyniU",
        "colab_type": "code",
        "outputId": "9791f1bf-4fa4-45b3-c49b-1b9d2196e657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# ---------------\n",
        "# GAN evaluation\n",
        "# ---------------\n",
        "\n",
        "# TODO: turn this into a general function and move it to its own section\n",
        "def evaulate_gan(test_model):\n",
        "  z = Variable(Tensor(np.random.normal(0, 1, (len(tox_data_train), gan_opt.latent_dim))))\n",
        "\n",
        "  gen = test_model(z)\n",
        "  peptides = decode_peptide_s(gen)\n",
        "  peptides = np.unique(peptides)\n",
        "  peptides = one_hot_s(peptides)\n",
        "\n",
        "  gen_scores = tox_predictor(peptides.cuda())\n",
        "\n",
        "  data = torch.stack(tox_data_train[:len(tox_data_train)][0])\n",
        "  data_scores = tox_predictor(data.cuda())\n",
        "\n",
        "  colors = ['red', 'blue']\n",
        "  labels = ['generated peptides', 'toxic peptides']\n",
        "  plt.hist(\n",
        "      [gen_scores.detach().cpu().numpy(), data_scores.detach().cpu().numpy()], \n",
        "      bins=10, density=True, histtype='bar', color=colors, label=labels)\n",
        "  plt.legend(prop={'size': 10})\n",
        "  plt.title('distribution of peptide data')\n",
        "\n",
        "load_model(generator, \"tox_generator.pt\")\n",
        "load_model(tox_predictor, \"tox_classifier.pt\")\n",
        "evaulate_gan(generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqIkuC4dz0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMg33Z8dtOQu",
        "colab_type": "text"
      },
      "source": [
        "# Data Genreation\n",
        "\n",
        "code that takes the original dataset and modifies it to be better/ more usable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKi8V7YR2WGj",
        "colab_type": "text"
      },
      "source": [
        "# Toxic Peptide Hall Of Fame\n",
        "\n",
        "All the best most toxic peptides that get generated should get stuck here along with their score so we don't loose track of them\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE0Dq3r4U1oj",
        "colab_type": "text"
      },
      "source": [
        "# Tests\n",
        "\n",
        "Please ignore everything bellow this line. This is garbage code just used for testing random things.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iEK8ku8U-7O",
        "colab_type": "code",
        "outputId": "1a2dd1ed-4013-42c3-e20f-7fe8cad765e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "sequences = np.load(\"mostToxicNCSequences.npy\")\n",
        "scores = np.load(\"mostToxicNCScores.npy\")\n",
        "print(len(sequences))\n",
        "print(sequences[:5]) #Why are these peptides 7 aa's long? That seems wrong?\n",
        "\n",
        "\n",
        "import csv\n",
        "\n",
        "# Repair old data\n",
        "new_sequences = []\n",
        "with open('all_data_filtered.csv') as csv_file:\n",
        "  csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "  line_count = 0\n",
        "  pbar = tqdm(total=45957)\n",
        "  for row in csv_reader:\n",
        "    line_count += 1\n",
        "    for i, sequence in enumerate(sequences):\n",
        "      if sequence in row[0] and scores[i] == row[1]:\n",
        "        pbar.update()\n",
        "        new_sequences.append(row[0])\n",
        "\n",
        "  print(f'Processed {line_count} lines.')\n",
        "\n",
        "print(len(new_sequences))\n",
        "print(new_sequences[:5])\n",
        "\n",
        "np.save(\"newMostToxicNCSequences\", new_sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 4/45957 [00:00<21:02, 36.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "45957\n",
            "['DCHRGFV' 'YRCCIIV' 'VCVHFLC' 'CCDIYVC' 'HCFCFDI']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 45954/45957 [25:52<00:00, 28.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Processed 105416 lines.\n",
            "45957\n",
            "['CDCHRGFV', 'IYRCCIIV', 'HVCVHFLC', 'DCCDIYVC', 'FHCFCFDI']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}